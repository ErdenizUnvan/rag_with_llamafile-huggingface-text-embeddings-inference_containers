

# Yeni klasörü oluşturun /home/kc icinde ve içine girin 

mkdir ~/bge-project 
cd ~/bge-project 

# Python scriptini oluşturalım 

cat > download_bge_model.py << EOF 

from huggingface_hub import snapshot_download 
model_name = "BAAI/bge-large-en-v1.5" 
# Model dosyalarını mevcut klasöre indiriyoruz 

snapshot_download(repo_id=model_name, local_dir=".", local_dir_use_symlinks=False) 
print(f"Model {model_name} bu klasöre indirildi.") 
EOF 
# Scripti çalıştırıp modeli indirelim 
python3 download_bge_model.py



cat> Dockerfile

# Base: HF Text Embeddings Inference (CPU)
FROM ghcr.io/huggingface/text-embeddings-inference:cpu-1.8

WORKDIR /app
# Build context’taki model klasörünü image içine kopyalıyoruz
COPY . /app/model

# TEI argümanları: model yolu
CMD ["--model-id", "/app/model"]

# Container içi port (TEI default: 80)
EXPOSE 80


docker build -t bge-tei:1.8 .

docker run -d --rm --name tei-bge \
  -p 8082:80 \
  bge-tei:1.8


#test
curl -X POST http://10.1.100.45:8082/embed \
  -H "Content-Type: application/json" \
  -d '{"inputs":["hello world","this is a test"],"truncate": true}'